## Token与字符

通常在说模型支持10K的上下文，是指模型一次最大可处理10K个token。token和我们平时使用的字词是不同的，一个token可以是一个单词、一个汉字或者一个词组，甚至一个标点符号。

另外，不同的模型采用的分词（Tokenizer ）方式不同，token和字符间对应关系也不同：

```python
import transformers

chat_tokenizer_dir = "./"

tokenizer = transformers.AutoTokenizer.from_pretrained(
    chat_tokenizer_dir, trust_remote_code=True
)

token_ids = tokenizer.encode("大模型是未来的趋势")
for tid in token_ids:
    print(tid, tokenizer.decode([tid]))
```



> 参考：[Token 用量计算 | DeepSeek API Docs](https://api-docs.deepseek.com/zh-cn/quick_start/token_usage)